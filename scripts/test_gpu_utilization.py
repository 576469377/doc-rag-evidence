#!/usr/bin/env python3
"""
å®æ—¶ç›‘æ§ColPaliç´¢å¼•æ„å»ºçš„GPUåˆ©ç”¨ç‡
"""
import sys
import subprocess
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

def monitor_gpu():
    """è·å–GPU 2çš„ä½¿ç”¨æƒ…å†µ"""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=memory.used,memory.total,utilization.gpu", 
             "--format=csv,noheader,nounits", "-i", "2"],
            capture_output=True, text=True, timeout=1
        )
        if result.returncode == 0:
            parts = result.stdout.strip().split(',')
            mem_used = int(parts[0].strip())
            mem_total = int(parts[1].strip())
            gpu_util = int(parts[2].strip())
            return mem_used, mem_total, gpu_util
    except:
        pass
    return None, None, None

def test_build_with_monitor():
    """æµ‹è¯•ç´¢å¼•æ„å»ºå¹¶ç›‘æ§GPU"""
    import yaml
    from core.schemas import AppConfig
    from infra.store_local import DocumentStoreLocal
    from impl.index_colpali import ColPaliRetriever
    
    # Load config
    with open("configs/app.yaml", "r") as f:
        config_dict = yaml.safe_load(f)
    config = AppConfig(**config_dict)
    
    store = DocumentStoreLocal(config)
    
    # Get test pages from docs directory
    docs_dir = Path(config.docs_dir)
    all_pages = []
    
    for doc_dir in sorted(docs_dir.iterdir()):
        if not doc_dir.is_dir():
            continue
        doc_id = doc_dir.name
        pages_dir = doc_dir / "pages"
        if not pages_dir.exists():
            continue
        
        for page_dir in sorted(pages_dir.iterdir()):
            if not page_dir.is_dir():
                continue
            try:
                page_id = int(page_dir.name)
                all_pages.append((doc_id, page_id))
            except ValueError:
                continue
    
    if not all_pages:
        print("âŒ No pages found")
        return
    
    test_pages = all_pages[:16]  # Test with 16 pages to see batch effect
    
    print("=" * 70)
    print(f"ColPaliæ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•")
    print("=" * 70)
    print(f"æµ‹è¯•é¡µé¢: {len(test_pages)}")
    print(f"Batch size: 16")
    print(f"GPU: cuda:2")
    print()
    
    # Load model
    print("â³ åŠ è½½ColPaliæ¨¡å‹...")
    retriever = ColPaliRetriever(
        model_name=config.colpali["model"],
        device="cuda:2",
        cache_dir=Path("data/cache/colpali_embeddings")
    )
    
    # Monitor baseline
    mem_used, mem_total, gpu_util = monitor_gpu()
    if mem_used:
        print(f"ğŸ“Š æ¨¡å‹åŠ è½½å: GPUæ˜¾å­˜ {mem_used}/{mem_total} MB ({mem_used/mem_total*100:.1f}%), åˆ©ç”¨ç‡ {gpu_util}%")
    
    print()
    print("â³ å¼€å§‹æ„å»ºç´¢å¼•...")
    print("   (è§‚å¯ŸGPUåˆ©ç”¨ç‡åº”è¯¥å‡é«˜åˆ° 60-90%)")
    print()
    
    # Start building
    import threading
    building = [True]
    max_util = [0]
    max_mem = [0]
    
    def monitor_thread():
        while building[0]:
            mem_used, mem_total, gpu_util = monitor_gpu()
            if mem_used:
                max_util[0] = max(max_util[0], gpu_util)
                max_mem[0] = max(max_mem[0], mem_used)
                print(f"\rğŸ“Š å®æ—¶: GPUæ˜¾å­˜ {mem_used}/{mem_total} MB ({mem_used/mem_total*100:.1f}%), åˆ©ç”¨ç‡ {gpu_util}%", end='', flush=True)
            time.sleep(0.5)
    
    monitor = threading.Thread(target=monitor_thread, daemon=True)
    monitor.start()
    
    start = time.time()
    retriever.build_index(test_pages, config=config)
    elapsed = time.time() - start
    
    building[0] = False
    time.sleep(0.6)
    print()
    
    print()
    print("=" * 70)
    print("ç»“æœ")
    print("=" * 70)
    print(f"âœ… æ„å»ºå®Œæˆ")
    print(f"   æ€»è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"   å¹³å‡/é¡µ: {elapsed/len(test_pages):.2f}ç§’")
    print(f"   ååé‡: {len(test_pages)/elapsed:.2f} pages/sec")
    print()
    print(f"ğŸ“Š GPUå³°å€¼:")
    print(f"   æœ€å¤§æ˜¾å­˜: {max_mem[0]} MB ({max_mem[0]/mem_total*100:.1f}%)")
    print(f"   æœ€å¤§åˆ©ç”¨ç‡: {max_util[0]}%")
    print()
    
    if max_util[0] < 50:
        print("âš ï¸  GPUåˆ©ç”¨ç‡åä½ï¼Œå¯èƒ½åŸå› ï¼š")
        print("   1. å›¾åƒå·²ç¼“å­˜ï¼Œè·³è¿‡äº†å®é™…è®¡ç®—")
        print("   2. batch_sizeå¤ªå°ï¼Œå¯ä»¥å¢å¤§åˆ°24æˆ–32")
        print("   3. CPUé¢„å¤„ç†æˆä¸ºç“¶é¢ˆï¼ˆå›¾åƒè§£ç ï¼‰")
    elif max_util[0] < 80:
        print("âœ… GPUåˆ©ç”¨ç‡æ­£å¸¸ï¼ˆ50-80%æ˜¯åˆç†èŒƒå›´ï¼‰")
    else:
        print("ğŸš€ GPUåˆ©ç”¨ç‡å¾ˆé«˜ï¼ˆ>80%ï¼‰ï¼Œæ‰¹é‡å¤„ç†æ•ˆæœæ˜¾è‘—ï¼")

if __name__ == "__main__":
    test_build_with_monitor()
