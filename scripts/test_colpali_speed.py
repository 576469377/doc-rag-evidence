#!/usr/bin/env python3
"""
æµ‹è¯•ColPaliæ£€ç´¢æ€§èƒ½ï¼ˆä¼˜åŒ–å‰åå¯¹æ¯”ï¼‰
"""
import sys
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import yaml
from core.schemas import AppConfig, QueryInput
from impl.index_colpali import ColPaliRetriever

def test_colpali_speed():
    # Load config
    with open("configs/app.yaml", "r") as f:
        config_dict = yaml.safe_load(f)
    config = AppConfig(**config_dict)
    
    # Load ColPali index
    index_dir = Path("data/indices/colpali_default")
    if not index_dir.exists():
        print("âŒ ColPaliç´¢å¼•ä¸å­˜åœ¨")
        return
    
    print("=" * 70)
    print("ColPaliæ£€ç´¢æ€§èƒ½æµ‹è¯•")
    print("=" * 70)
    
    retriever = ColPaliRetriever.load(
        index_dir,
        model_name=config.colpali["model"],
        device="cuda:2"
    )
    
    print(f"\nâœ… å·²åŠ è½½ç´¢å¼•: {len(retriever.store.page_ids)} é¡µ")
    
    # Test queries
    test_queries = [
        "ç£·é…¸æ°¢é’™çš„ä¸»è¦åŸæ–™æœ‰å“ªäº›ï¼Ÿ",
        "é£Ÿå“æ·»åŠ å‰‚çš„æŠ€æœ¯è¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ",
        "äº§å“çš„æ„Ÿå®˜è¦æ±‚æœ‰å“ªäº›è§„å®šï¼Ÿ"
    ]
    
    print(f"\næµ‹è¯•æŸ¥è¯¢æ•°é‡: {len(test_queries)}")
    print(f"Top-K: {config.top_k_retrieve}")
    print(f"Coarse-K: {retriever.max_global_pool_pages}")
    
    # Warm up
    print("\nâ³ é¢„çƒ­ä¸­...")
    retriever.retrieve(test_queries[0], config=config)
    
    # Benchmark
    print("\n" + "â”€" * 70)
    print("æ€§èƒ½æµ‹è¯•å¼€å§‹")
    print("â”€" * 70)
    
    total_time = 0
    for i, query in enumerate(test_queries, 1):
        start = time.time()
        result = retriever.retrieve(
            QueryInput(query_id=f"test_{i}", question=query),
            config=config
        )
        elapsed = time.time() - start
        total_time += elapsed
        
        print(f"\næŸ¥è¯¢ {i}: {query}")
        print(f"  â±ï¸  è€—æ—¶: {elapsed:.3f}ç§’ ({result.elapsed_ms}ms)")
        print(f"  ğŸ“„ ç»“æœæ•°: {len(result.hits)}")
        if result.hits:
            print(f"  ğŸ† Top-1: {result.hits[0].doc_id} page {result.hits[0].page_id} (score: {result.hits[0].score:.4f})")
    
    avg_time = total_time / len(test_queries)
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç»“æœ")
    print("=" * 70)
    print(f"æ€»è€—æ—¶: {total_time:.3f}ç§’")
    print(f"å¹³å‡æ¯æ¬¡æŸ¥è¯¢: {avg_time:.3f}ç§’")
    print(f"æŸ¥è¯¢é€Ÿç‡: {1/avg_time:.2f} queries/sec")
    
    # Performance breakdown
    print(f"\næ€§èƒ½åˆ†æ:")
    print(f"  â€¢ ç´¢å¼•é¡µé¢æ•°: {len(retriever.store.page_ids)}")
    print(f"  â€¢ Coarseæ£€ç´¢å€™é€‰æ•°: {retriever.max_global_pool_pages}")
    print(f"  â€¢ å¹¶è¡Œworkeræ•°: 8 (ThreadPoolExecutor)")
    print(f"  â€¢ åŠ é€Ÿæ•ˆæœ: çº¦ {retriever.max_global_pool_pages / 8:.1f}x (ç†è®ºä¸Š)")

if __name__ == "__main__":
    test_colpali_speed()
