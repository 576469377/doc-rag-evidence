"""
Enhanced Gradio UI V1 for doc-rag-evidence system.
Supports multiple retrieval modes: BM25, Dense, ColPali, Hybrid.
"""
from __future__ import annotations

import os
import uuid
import yaml
from pathlib import Path
from typing import Optional, List, Tuple
import sys

# Clear proxy settings to avoid localhost connection issues
for proxy_var in ['http_proxy', 'https_proxy', 'HTTP_PROXY', 'HTTPS_PROXY', 
                  'all_proxy', 'ALL_PROXY', 'no_proxy', 'NO_PROXY']:
    os.environ.pop(proxy_var, None)

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    import gradio as gr
except ImportError:
    gr = None

from core.schemas import AppConfig, QueryInput
from core.pipeline import Pipeline
from infra.store_local import DocumentStoreLocal
from infra.runlog_local import RunLoggerLocal
from impl.ingest_pdf_v1 import PDFIngestorV1
from impl.index_incremental import IncrementalIndexManager
from impl.index_bm25 import BM25IndexerRetriever
from impl.index_dense import DenseIndexerRetriever, VLLMEmbedder
from impl.index_colpali import ColPaliRetriever
from impl.selector_topk import TopKEvidenceSelector
from impl.generator_template import TemplateGenerator
from impl.eval_runner import EvalRunner


class DocRAGUIV1:
    """Enhanced Gradio UI with multi-mode retrieval."""

    def __init__(self, config_path: str = "configs/app.yaml"):
        # Load config
        with open(config_path, "r") as f:
            config_dict = yaml.safe_load(f)
        self.config = AppConfig(**config_dict)

        # Initialize infrastructure
        self.store = DocumentStoreLocal(self.config)
        self.logger = RunLoggerLocal(self.config)
        
        # Initialize retrievers
        self.retrievers = {}
        self._init_retrievers()
        
        # Initialize other components
        self.selector = TopKEvidenceSelector(snippet_length=500)
        
        # Initialize generator based on config
        generator_type = self.config.generator.get("type", "template")
        if generator_type == "qwen3_vl":
            try:
                from impl.generator_qwen_llm import QwenLLMGenerator
                self.generator = QwenLLMGenerator(self.config)
                print(f"âœ… Using QwenLLMGenerator")
            except Exception as e:
                print(f"âš ï¸  Failed to load QwenLLMGenerator: {e}, falling back to template")
                from impl.generator_template import TemplateGenerator
                self.generator = TemplateGenerator(mode="summary")
        else:
            from impl.generator_template import TemplateGenerator
            self.generator = TemplateGenerator(mode="summary")
            print(f"âœ… Using TemplateGenerator")
        
        # Create pipeline (default retriever) with store for hit normalization
        default_retriever = self.retrievers.get(self.config.retrieval_mode)
        if not default_retriever:
            default_retriever = self.retrievers.get("bm25")
        
        self.pipeline = Pipeline(
            retriever=default_retriever,
            selector=self.selector,
            generator=self.generator,
            logger=self.logger,
            reranker=None,
            store=self.store  # Enable hit normalization
        )
        
        # Eval runner
        self.eval_runner = EvalRunner(self.pipeline)
        
        print(f"UI initialized with config: {config_path}")
        print(f"Available retrieval modes: {list(self.retrievers.keys())}")

    def _init_retrievers(self):
        """Initialize available retrievers based on config."""
        indices_dir = Path(self.config.indices_dir)
        
        # BM25 (always try to load)
        bm25_index_name = "bm25_default"
        try:
            retriever = BM25IndexerRetriever(self.store)
            retriever.load(self.config, index_name=bm25_index_name)
            self.retrievers["bm25"] = retriever
            print(f"âœ… Loaded BM25 index: {len(retriever.units)} units")
        except Exception as e:
            print(f"âŒ Failed to load BM25 index: {e}")
        
        # Dense (vLLM embedding)
        if self.config.dense.get("enabled"):
            dense_index_name = "dense_default"
            dense_index_dir = indices_dir / dense_index_name
            if dense_index_dir.exists():
                try:
                    embedder = VLLMEmbedder(
                        endpoint=self.config.dense["endpoint"],
                        model=self.config.dense["model"],
                        batch_size=self.config.dense.get("batch_size", 32)
                    )
                    retriever = DenseIndexerRetriever.load(dense_index_dir, embedder)
                    self.retrievers["dense"] = retriever
                    print(f"âœ… Loaded Dense index: {len(retriever.units)} units (vLLM @ {self.config.dense['endpoint']})")
                except Exception as e:
                    print(f"âŒ Failed to load Dense index: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"âš ï¸  Dense index not found at {dense_index_dir}")
        
        # ColPali (vision embedding on GPU 2) - å»¶è¿ŸåŠ è½½ï¼Œåªè®°å½•é…ç½®
        if self.config.colpali.get("enabled"):
            colpali_index_name = "colpali_default"
            colpali_index_dir = indices_dir / colpali_index_name
            if colpali_index_dir.exists():
                # ä¸ç«‹å³åŠ è½½æ¨¡åž‹ï¼Œåªæ³¨å†Œå¯ç”¨æ€§
                self.retrievers["colpali"] = None  # Placeholderï¼Œå»¶è¿ŸåŠ è½½
                self._colpali_config = {
                    "index_dir": colpali_index_dir,
                    "model_name": self.config.colpali["model"],
                    "device": self.config.colpali.get("device", "cuda:2")
                }
                print(f"âœ… ColPali index available (å»¶è¿ŸåŠ è½½æ¨¡å¼)")
            else:
                print(f"âš ï¸  ColPali index not found at {colpali_index_dir}")
        
        # Initialize hybrid retrievers if multiple methods available
        self._init_hybrid_retrievers()

    def _init_hybrid_retrievers(self):
        """Initialize hybrid retrieval combinations."""
        available = [k for k, v in self.retrievers.items() if v is not None or k == "colpali"]
        
        # Dense + ColPali hybrid
        if "dense" in available and "colpali" in available:
            from impl.retriever_hybrid import HybridRetriever
            # Placeholder for lazy initialization
            self.retrievers["hybrid_dense_colpali"] = "lazy"
            print(f"âœ… Hybrid (Dense+ColPali) available (å»¶è¿ŸåŠ è½½)")
        
        # BM25 + Dense hybrid  
        if "bm25" in available and "dense" in available:
            from impl.retriever_hybrid import HybridRetriever
            self.retrievers["hybrid_bm25_dense"] = HybridRetriever(
                retrievers={"bm25": self.retrievers["bm25"], "dense": self.retrievers["dense"]},
                weights={"bm25": 0.4, "dense": 0.6},
                fusion_method="weighted_sum"
            )
            print(f"âœ… Hybrid (BM25+Dense) initialized")

    def launch(self, share: bool = False):
        """Launch Gradio UI."""
        if gr is None:
            raise ImportError("gradio is required. Install with: pip install gradio")

        with gr.Blocks(title="Doc RAG Evidence System V1") as demo:
            gr.Markdown("# ðŸ“š Document RAG Evidence System V1")
            gr.Markdown("Multi-modal document retrieval with BM25 / Dense / ColPali support")

            with gr.Tabs():
                # Tab 1: Document Management
                with gr.Tab("ðŸ“„ Document Management"):
                    self._build_document_tab()

                # Tab 2: Query & Answer
                with gr.Tab("ðŸ” Query & Answer"):
                    self._build_query_tab()

                # Tab 3: Evaluation
                with gr.Tab("ðŸ“Š Evaluation"):
                    self._build_eval_tab()

        try:
            demo.launch(
                share=share, 
                server_name="127.0.0.1",  # Changed from 0.0.0.0 to fix 502 error
                server_port=7860,
                show_error=True,
                quiet=False
            )
        except Exception as e:
            print(f"âŒ Failed to launch Gradio: {e}")
            # Try alternative port
            print("âš ï¸  Trying alternative port 7861...")
            demo.launch(
                share=share,
                server_name="127.0.0.1",
                server_port=7861,
                show_error=True
            )

    def _build_document_tab(self):
        """Build document management tab."""
        gr.Markdown("## Upload and Manage Documents")

        # Section 1: Upload & Ingest
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ðŸ“¤ Upload PDF (Supports Multiple Files)")
                pdf_files = gr.File(
                    label="Upload PDF(s)", 
                    file_types=[".pdf"],
                    file_count="multiple",
                    type="filepath"
                )
                use_ocr = gr.Checkbox(label="Use OCR (slower, better quality)", value=False)
                upload_btn = gr.Button("ðŸ“¤ Ingest Document(s)", variant="primary")
                upload_status = gr.Textbox(label="Ingestion Status", lines=8, interactive=False)

            with gr.Column():
                gr.Markdown("### ðŸ“š Document List")
                refresh_btn = gr.Button("ðŸ”„ Refresh Document List")
                doc_list = gr.Dataframe(
                    headers=["Doc ID", "Title", "Pages", "Created At"],
                    label="Documents",
                    interactive=False
                )
                delete_docid = gr.Textbox(label="Document ID to Delete", placeholder="Enter doc_id")
                delete_btn = gr.Button("ðŸ—‘ï¸ Delete Document", variant="stop")
                delete_status = gr.Textbox(label="Delete Status", lines=1, interactive=False)

        gr.Markdown("---")
        
        # Section 2: Build Indices
        gr.Markdown("### ðŸ”§ Build Indices")
        gr.Markdown("After uploading documents, build indices for retrieval")
        
        with gr.Row():
            with gr.Column():
                build_bm25 = gr.Checkbox(label="Build BM25 Index (keyword search)", value=True)
                build_dense = gr.Checkbox(label="Build Dense Index (semantic embedding)", value=False)
                build_colpali = gr.Checkbox(label="Build ColPali Index (vision-based)", value=False)
                index_name_suffix = gr.Textbox(
                    label="Index Name Suffix (optional)",
                    placeholder="default",
                    value="default"
                )
                build_btn = gr.Button("âš™ï¸ Build Indices", variant="primary", size="lg")
                
            with gr.Column():
                build_status = gr.Textbox(
                    label="Build Status",
                    lines=10,
                    interactive=False,
                    placeholder="Status will appear here..."
                )

        # Event handlers
        upload_btn.click(
            fn=self._handle_batch_upload,
            inputs=[pdf_files, use_ocr],
            outputs=[upload_status, doc_list]
        )

        refresh_btn.click(
            fn=self._handle_refresh_docs,
            inputs=[],
            outputs=[doc_list]
        )

        delete_btn.click(
            fn=self._handle_delete_doc,
            inputs=[delete_docid],
            outputs=[delete_status, doc_list]
        )
        
        build_btn.click(
            fn=self._handle_build_indices,
            inputs=[build_bm25, build_dense, build_colpali, index_name_suffix],
            outputs=[build_status]
        )

    def _build_query_tab(self):
        """Build query & answer tab."""
        gr.Markdown("## Ask Questions")

        with gr.Row():
            with gr.Column(scale=1):
                # Retrieval mode selector
                retrieval_mode = gr.Radio(
                    choices=list(self.retrievers.keys()),
                    value=self.config.retrieval_mode if self.config.retrieval_mode in self.retrievers else list(self.retrievers.keys())[0],
                    label="Retrieval Mode",
                    info="BM25: keyword search | Dense: semantic embedding | ColPali: vision-based"
                )
                
                question = gr.Textbox(
                    label="Your Question",
                    placeholder="What is the main topic of the document?",
                    lines=3
                )
                doc_filter = gr.Textbox(
                    label="Filter by Doc IDs (comma-separated, optional)",
                    placeholder="doc1,doc2",
                    lines=1
                )
                query_btn = gr.Button("ðŸš€ Ask Question", variant="primary")

            with gr.Column(scale=2):
                answer_box = gr.Textbox(
                    label="Answer",
                    lines=8,
                    interactive=False
                )
        
        # Evidence format selector (outside columns for better visibility)
        evidence_mode = gr.Radio(
            choices=["text", "image"],
            value="text",
            label="Evidence Format",
            info="text: ä½¿ç”¨æ–‡æœ¬snippet | image: ä½¿ç”¨å®Œæ•´é¡µé¢å›¾ç‰‡ï¼ˆæ›´å‡†ç¡®ï¼Œé€‚åˆVLæ¨¡åž‹ï¼‰"
        )
        
        # Hybrid fusion settings (collapsible)
        with gr.Accordion("âš™ï¸ Hybrid Fusion Settings (ä»…å¯¹ Hybrid æ¨¡å¼ç”Ÿæ•ˆ)", open=False):
            gr.Markdown("### è‡ªå®šä¹‰æ··åˆæ£€ç´¢é…ç½®")
            
            with gr.Row():
                with gr.Column():
                    fusion_method = gr.Radio(
                        choices=["weighted_sum", "rrf"],
                        value="weighted_sum",
                        label="Fusion Method (èžåˆæ–¹æ³•)",
                        info="weighted_sum: åŠ æƒåˆ†æ•°èžåˆ | rrf: å€’æ•°æŽ’åèžåˆ"
                    )
                    
                    gr.Markdown("""
                    #### èžåˆæ–¹æ³•è¯´æ˜Ž
                    - **Weighted Sum**: å°†å„æ£€ç´¢å™¨çš„åˆ†æ•°å½’ä¸€åŒ–åŽåŠ æƒæ±‚å’Œ
                      - è€ƒè™‘åˆ†æ•°å¤§å°ï¼Œé«˜åˆ†æ–‡æ¡£ä¼˜åŠ¿æ˜Žæ˜¾
                      - é€‚ç”¨ï¼šæ£€ç´¢å™¨åˆ†æ•°æœ‰æ˜Žç¡®ç‰©ç†æ„ä¹‰
                    
                    - **RRF (Reciprocal Rank Fusion)**: åªè€ƒè™‘æŽ’åä½ç½®
                      - å…¬å¼ï¼šscore = sum(1 / (60 + rank))
                      - å¯¹åˆ†æ•°å°ºåº¦ä¸æ•æ„Ÿï¼Œæ›´é²æ£’
                      - é€‚ç”¨ï¼šå¤šä¸ªæ£€ç´¢å™¨åˆ†æ•°èŒƒå›´å·®å¼‚å¤§æ—¶
                    """)
                
                with gr.Column():
                    gr.Markdown("#### æ£€ç´¢å™¨é€‰æ‹©ä¸Žæƒé‡")
                    
                    retriever_1 = gr.Dropdown(
                        choices=["bm25", "dense", "colpali"],
                        value="bm25",
                        label="First Retriever (æ£€ç´¢å™¨1)",
                        info="é€‰æ‹©ç¬¬ä¸€ä¸ªæ£€ç´¢å™¨"
                    )
                    
                    retriever_2 = gr.Dropdown(
                        choices=["bm25", "dense", "colpali"],
                        value="dense",
                        label="Second Retriever (æ£€ç´¢å™¨2)",
                        info="é€‰æ‹©ç¬¬äºŒä¸ªæ£€ç´¢å™¨"
                    )
                    
                    weight_1 = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        value=0.4,
                        step=0.05,
                        label="Weight of First Retriever",
                        info="ç¬¬ä¸€ä¸ªæ£€ç´¢å™¨çš„æƒé‡ï¼ˆç¬¬äºŒä¸ªè‡ªåŠ¨ä¸º 1 - weight_1ï¼‰"
                    )
                    
                    weight_display = gr.Markdown(
                        "**å½“å‰æƒé‡**: æ£€ç´¢å™¨1 = 0.40, æ£€ç´¢å™¨2 = 0.60"
                    )
            
            gr.Markdown("---")
            gr.Markdown("ðŸ’¡ **å¿«é€Ÿé…ç½®**: é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ£€ç´¢å™¨ï¼Œè°ƒæ•´æƒé‡æ»‘å—ï¼Œç‚¹å‡» 'Ask Question' åº”ç”¨é…ç½®")
            
            # Update weight display when slider changes
            def update_weight_display(w1):
                w2 = 1.0 - w1
                return f"**å½“å‰æƒé‡**: æ£€ç´¢å™¨1 = {w1:.2f}, æ£€ç´¢å™¨2 = {w2:.2f}"
            
            weight_1.change(
                fn=update_weight_display,
                inputs=[weight_1],
                outputs=[weight_display]
            )

        gr.Markdown("### ðŸ“‘ Evidence")
        evidence_display = gr.Dataframe(
            headers=["Rank", "Source", "Doc ID", "Page", "Score", "Snippet"],
            label="Retrieved Evidence",
            interactive=False
        )

        query_id_box = gr.Textbox(label="Query ID (for traceability)", interactive=False)

        # Event handler
        query_btn.click(
            fn=self._handle_query,
            inputs=[
                question, 
                doc_filter, 
                retrieval_mode, 
                evidence_mode,
                fusion_method,
                retriever_1,
                retriever_2,
                weight_1
            ],
            outputs=[answer_box, evidence_display, query_id_box]
        )

    def _build_eval_tab(self):
        """Build evaluation tab."""
        gr.Markdown("## Batch Evaluation")

        with gr.Row():
            with gr.Column():
                eval_file = gr.File(label="Upload Eval Dataset (CSV or JSON)", file_types=[".csv", ".json"])
                eval_mode = gr.Radio(
                    choices=list(self.retrievers.keys()),
                    value=list(self.retrievers.keys())[0],
                    label="Retrieval Mode for Evaluation"
                )
                
                # Hybrid fusion settings for evaluation
                with gr.Accordion("âš™ï¸ Hybrid Fusion Settings (ä»…å¯¹ Hybrid æ¨¡å¼ç”Ÿæ•ˆ)", open=False):
                    gr.Markdown("### è¯„ä¼°ä¸­çš„æ··åˆæ£€ç´¢é…ç½®")
                    
                    with gr.Row():
                        with gr.Column():
                            eval_fusion_method = gr.Radio(
                                choices=["weighted_sum", "rrf"],
                                value="weighted_sum",
                                label="Fusion Method",
                                info="weighted_sum: åŠ æƒåˆ†æ•° | rrf: å€’æ•°æŽ’å"
                            )
                        
                        with gr.Column():
                            eval_retriever_1 = gr.Dropdown(
                                choices=["bm25", "dense", "colpali"],
                                value="bm25",
                                label="First Retriever",
                                info="é€‰æ‹©ç¬¬ä¸€ä¸ªæ£€ç´¢å™¨"
                            )
                            
                            eval_retriever_2 = gr.Dropdown(
                                choices=["bm25", "dense", "colpali"],
                                value="dense",
                                label="Second Retriever",
                                info="é€‰æ‹©ç¬¬äºŒä¸ªæ£€ç´¢å™¨"
                            )
                            
                            eval_weight_1 = gr.Slider(
                                minimum=0.0,
                                maximum=1.0,
                                value=0.4,
                                step=0.05,
                                label="Weight of First Retriever",
                                info="ç¬¬ä¸€ä¸ªæ£€ç´¢å™¨çš„æƒé‡"
                            )
                            
                            eval_weight_display = gr.Markdown(
                                "**å½“å‰æƒé‡**: æ£€ç´¢å™¨1 = 0.40, æ£€ç´¢å™¨2 = 0.60"
                            )
                    
                    gr.Markdown("ðŸ’¡ Hybrid æ¨¡å¼ä¸‹ï¼Œå°†ä½¿ç”¨ä»¥ä¸Šé…ç½®è¿›è¡Œæ‰¹é‡è¯„ä¼°")
                    
                    # Update weight display
                    def update_eval_weight_display(w1):
                        w2 = 1.0 - w1
                        return f"**å½“å‰æƒé‡**: æ£€ç´¢å™¨1 = {w1:.2f}, æ£€ç´¢å™¨2 = {w2:.2f}"
                    
                    eval_weight_1.change(
                        fn=update_eval_weight_display,
                        inputs=[eval_weight_1],
                        outputs=[eval_weight_display]
                    )
                
                eval_btn = gr.Button("â–¶ï¸ Run Evaluation", variant="primary")
                eval_status = gr.Textbox(label="Evaluation Status", lines=5, interactive=False)

            with gr.Column():
                eval_metrics = gr.JSON(label="Metrics")
                download_csv = gr.File(label="Download predictions.csv")
                download_json = gr.File(label="Download report.json")

        # Event handler
        eval_btn.click(
            fn=self._handle_eval,
            inputs=[
                eval_file, 
                eval_mode,
                eval_fusion_method,
                eval_retriever_1,
                eval_retriever_2,
                eval_weight_1
            ],
            outputs=[eval_status, eval_metrics, download_csv, download_json]
        )

    # ========== Event Handlers ==========

    def _handle_batch_upload(self, pdf_files, use_ocr: bool) -> Tuple[str, List]:
        """Handle batch PDF upload and ingestion."""
        try:
            if pdf_files is None or len(pdf_files) == 0:
                return "âŒ Error: No files uploaded", self._get_doc_list()
            
            # Handle single file or multiple files
            if not isinstance(pdf_files, list):
                pdf_files = [pdf_files]
            
            total_files = len(pdf_files)
            status_lines = []
            status_lines.append(f"ðŸ“¦ Batch Upload: {total_files} file(s)")
            status_lines.append("=" * 50)
            
            if use_ocr:
                status_lines.append("âš™ï¸ OCR enabled - processing may take time...")
            status_lines.append("")
            
            # Process each file
            success_count = 0
            failed_count = 0
            ingested_docs = []
            
            for idx, pdf_file in enumerate(pdf_files, 1):
                try:
                    filename = Path(pdf_file.name).name
                    status_lines.append(f"[{idx}/{total_files}] Processing: {filename}")
                    
                    # Ingest with V1 ingestor
                    ingestor = PDFIngestorV1(
                        config=self.config,
                        store=self.store,
                        use_ocr=use_ocr
                    )
                    
                    meta = ingestor.ingest(pdf_file.name)
                    
                    status_lines.append(f"  âœ… Success: {meta.doc_id} ({meta.page_count} pages)")
                    ingested_docs.append(meta.doc_id)
                    success_count += 1
                    
                except Exception as e:
                    status_lines.append(f"  âŒ Failed: {str(e)}")
                    failed_count += 1
                
                status_lines.append("")  # Blank line between files
            
            # Summary
            status_lines.append("=" * 50)
            status_lines.append(f"ðŸ“Š Summary:")
            status_lines.append(f"  âœ… Success: {success_count}/{total_files}")
            status_lines.append(f"  âŒ Failed: {failed_count}/{total_files}")
            
            if success_count > 0:
                status_lines.append(f"\n  Ingested IDs: {', '.join(ingested_docs)}")
                status_lines.append("\nâš ï¸ Next Step: Build indices below to enable retrieval")
            
            return "\n".join(status_lines), self._get_doc_list()
            
        except Exception as e:
            import traceback
            error_msg = f"âŒ Batch Upload Error: {str(e)}\n\nDetails:\n{traceback.format_exc()}"
            return error_msg, self._get_doc_list()
    
    def _handle_upload(self, pdf_file, use_ocr: bool) -> Tuple[str, List]:
        """Handle single PDF upload (legacy, kept for compatibility)."""
        # Redirect to batch handler
        return self._handle_batch_upload([pdf_file] if pdf_file else None, use_ocr)

    def _handle_build_indices(
        self,
        build_bm25: bool,
        build_dense: bool,
        build_colpali: bool,
        index_name_suffix: str
    ) -> str:
        """Handle index building (now with incremental updates)."""
        try:
            if not any([build_bm25, build_dense, build_colpali]):
                return "âŒ Error: Please select at least one index type to build"

            status = "ðŸ”§ Building/Updating Indices (Incremental Mode)...\n\n"
            suffix = index_name_suffix.strip() or "default"
            
            # Get all documents
            docs = self.store.list_documents()
            if not docs:
                return "âŒ Error: No documents found. Please ingest documents first."
            
            status += f"ðŸ“š Found {len(docs)} document(s)\n"
            
            # Initialize incremental index manager
            index_manager = IncrementalIndexManager(self.config, self.store)
            
            # BM25 incremental build/update
            if build_bm25:
                status += "\n" + "â”€" * 50 + "\n"
                status += "â³ BM25 Index Update\n"
                status += "â”€" * 50 + "\n"
                try:
                    result = index_manager.update_bm25_index(
                        index_name=f"bm25_{suffix}"
                    )
                    
                    if result["status"] == "success":
                        # Reload retriever
                        retriever = BM25IndexerRetriever(self.store)
                        retriever.load(self.config, index_name=f"bm25_{suffix}")
                        self.retrievers["bm25"] = retriever
                        
                        status += f"âœ… Success!\n"
                        status += f"   New documents: {result['new_docs']}\n"
                        status += f"   New units: {result['new_units']}\n"
                        status += f"   Total: {result['total_units']} units from {result['total_docs']} documents\n"
                    elif result["status"] == "no_update":
                        status += f"â„¹ï¸  {result['message']}\n"
                        status += f"   All documents already indexed\n"
                    else:
                        status += f"âŒ {result['message']}\n"
                except Exception as e:
                    import traceback
                    status += f"âŒ Error: {str(e)}\n"
                    status += f"{traceback.format_exc()}\n"
            
            # Dense incremental build/update
            if build_dense:
                status += "\n" + "â”€" * 50 + "\n"
                status += "â³ Dense Index Update\n"
                status += "â”€" * 50 + "\n"
                try:
                    result = index_manager.update_dense_index(
                        index_name=f"dense_{suffix}"
                    )
                    
                    if result["status"] == "success":
                        # Reload retriever with updated index
                        embedder = VLLMEmbedder(
                            endpoint=self.config.dense["endpoint"],
                            model=self.config.dense["model"],
                            batch_size=self.config.dense.get("batch_size", 32)
                        )
                        index_dir = Path(self.config.indices_dir) / f"dense_{suffix}"
                        retriever = DenseIndexerRetriever.load(index_dir, embedder)
                        self.retrievers["dense"] = retriever
                        
                        status += f"âœ… Success!\n"
                        status += f"   New documents: {result['new_docs']}\n"
                        status += f"   New units: {result['new_units']}\n"
                        status += f"   Total: {result['total_units']} units\n"
                        status += f"   vLLM endpoint: {self.config.dense['endpoint']}\n"
                    elif result["status"] == "no_update":
                        status += f"â„¹ï¸  {result['message']}\n"
                        status += f"   All documents already indexed\n"
                    else:
                        status += f"âŒ {result['message']}\n"
                except Exception as e:
                    import traceback
                    status += f"âŒ Error: {str(e)}\n"
                    status += f"{traceback.format_exc()}\n"
            
            # ColPali incremental build/update
            if build_colpali:
                status += "\n" + "â”€" * 50 + "\n"
                status += "â³ ColPali Index Update\n"
                status += "â”€" * 50 + "\n"
                try:
                    result = index_manager.update_colpali_index(
                        index_name=f"colpali_{suffix}"
                    )
                    
                    if result["status"] == "success":
                        # Reload retriever
                        device = self.config.colpali.get("device", "cuda:2")
                        retriever = ColPaliRetriever(
                            model_name=self.config.colpali["model"],
                            device=device,
                            max_global_pool_pages=self.config.colpali.get("max_global_pool", 100)
                        )
                        index_dir = Path(self.config.indices_dir) / f"colpali_{suffix}"
                        retriever.load_instance(index_dir)
                        self.retrievers["colpali"] = retriever
                        
                        status += f"âœ… Success!\n"
                        status += f"   New documents: {result['new_docs']}\n"
                        status += f"   New pages: {result['new_pages']}\n"
                        status += f"   Total: {result['total_pages']} pages\n"
                        status += f"   Device: {device}\n"
                    elif result["status"] == "no_update":
                        status += f"â„¹ï¸  {result['message']}\n"
                        status += f"   All documents already indexed\n"
                    else:
                        status += f"âŒ {result['message']}\n"
                except Exception as e:
                    import traceback
                    status += f"âŒ Error: {str(e)}\n"
                    status += f"{traceback.format_exc()}\n"
            
            status += "\n" + "=" * 50 + "\n"
            status += "ðŸŽ‰ Index Building Complete!\n"
            status += "=" * 50 + "\n"
            status += f"\nAvailable retrieval modes: {list(self.retrievers.keys())}\n"
            status += "\nâ„¹ï¸  Incremental indexing:\n"
            status += "   â€¢ Only new documents are indexed\n"
            status += "   â€¢ Existing indices are preserved and updated\n"
            status += "   â€¢ No need to rebuild everything when adding docs\n"
            status += "\nYou can now use the 'Query & Answer' tab.\n"
            
            return status
            
        except Exception as e:
            import traceback
            return f"âŒ Error: {str(e)}\n\n{traceback.format_exc()}"

    def _handle_refresh_docs(self) -> List:
        """Refresh document list."""
        return self._get_doc_list()

    def _handle_delete_doc(self, doc_id: str) -> Tuple[str, List]:
        """Delete a document."""
        try:
            if not doc_id:
                return "Error: No doc_id provided", self._get_doc_list()
            
            self.store.delete_document(doc_id)
            return f"âœ… Deleted: {doc_id}", self._get_doc_list()
            
        except Exception as e:
            return f"Error: {str(e)}", self._get_doc_list()

    def _handle_query(
        self,
        question: str,
        doc_filter: str,
        retrieval_mode: str,
        evidence_mode: str = "text",
        fusion_method: str = "weighted_sum",
        retriever_1: str = "bm25",
        retriever_2: str = "dense",
        weight_1: float = 0.4
    ) -> Tuple[str, List, str]:
        """Handle query with selected retrieval mode and evidence format."""
        try:
            if not question:
                return "Please enter a question", [], ""
            
            # Switch retriever (å»¶è¿ŸåŠ è½½ColPaliå’ŒHybrid)
            retriever = self.retrievers.get(retrieval_mode)
            
            # å¦‚æžœæ˜¯ColPaliä¸”è¿˜æœªåŠ è½½ï¼ŒçŽ°åœ¨åŠ è½½
            if retrieval_mode == "colpali" and retriever is None:
                if hasattr(self, "_colpali_config"):
                    try:
                        print(f"â³ é¦–æ¬¡ä½¿ç”¨ColPaliï¼Œæ­£åœ¨åŠ è½½æ¨¡åž‹...")
                        retriever = ColPaliRetriever.load(
                            self._colpali_config["index_dir"],
                            model_name=self._colpali_config["model_name"],
                            device=self._colpali_config["device"]
                        )
                        self.retrievers["colpali"] = retriever
                        print(f"âœ… ColPaliæ¨¡åž‹åŠ è½½å®Œæˆ")
                    except Exception as e:
                        return f"Failed to load ColPali: {e}", [], ""
                else:
                    return "ColPali not configured.", [], ""
            
            # åŠ¨æ€é‡å»º Hybrid retrieverï¼ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ£€ç´¢å™¨ç»„åˆã€æƒé‡å’Œèžåˆæ–¹æ³•ï¼‰
            if "hybrid" in retrieval_mode:
                from impl.retriever_hybrid import HybridRetriever
                
                # éªŒè¯ç”¨æˆ·é€‰æ‹©çš„ä¸¤ä¸ªæ£€ç´¢å™¨ä¸åŒ
                if retriever_1 == retriever_2:
                    return f"âš ï¸ è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ£€ç´¢å™¨ï¼å½“å‰éƒ½é€‰æ‹©äº† {retriever_1}", [], ""
                
                # ç¡®ä¿æ‰€éœ€çš„æ£€ç´¢å™¨å·²åŠ è½½
                retriever_objs = {}
                for ret_name in [retriever_1, retriever_2]:
                    if ret_name == "colpali" and self.retrievers.get("colpali") is None:
                        # åŠ¨æ€åŠ è½½ColPali
                        if hasattr(self, "_colpali_config"):
                            try:
                                print(f"â³ é¦–æ¬¡ä½¿ç”¨ColPaliï¼Œæ­£åœ¨åŠ è½½æ¨¡åž‹...")
                                colpali_retriever = ColPaliRetriever.load(
                                    self._colpali_config["index_dir"],
                                    model_name=self._colpali_config["model_name"],
                                    device=self._colpali_config["device"]
                                )
                                self.retrievers["colpali"] = colpali_retriever
                                print(f"âœ… ColPaliæ¨¡åž‹åŠ è½½å®Œæˆ")
                            except Exception as e:
                                return f"Failed to load ColPali: {e}", [], ""
                        else:
                            return f"ColPali not configured.", [], ""
                    
                    if ret_name not in self.retrievers:
                        return f"âš ï¸ æ£€ç´¢å™¨ '{ret_name}' æœªæ‰¾åˆ°ï¼Œè¯·å…ˆæž„å»ºç´¢å¼•", [], ""
                    
                    retriever_objs[ret_name] = self.retrievers[ret_name]
                
                # è®¡ç®—å½’ä¸€åŒ–æƒé‡
                weight_2 = 1.0 - weight_1
                weights = {retriever_1: weight_1, retriever_2: weight_2}
                
                # åˆ›å»º Hybrid retriever
                retriever = HybridRetriever(
                    retrievers=retriever_objs,
                    weights=weights,
                    fusion_method=fusion_method
                )
                
                print(f"ðŸ”„ Custom Hybrid ({retriever_1}+{retriever_2}) with {fusion_method}")
                print(f"   Weights: {retriever_1}={weight_1:.2f}, {retriever_2}={weight_2:.2f}")
            
            if retriever is None:
                return f"Retriever '{retrieval_mode}' not available. Please build indices first.", [], ""

            
            # Switch generator based on evidence mode
            if evidence_mode == "image":
                # Use image-based generator
                try:
                    from impl.generator_qwen_vl import QwenVLGenerator
                    generator = QwenVLGenerator(self.config, use_images=True, store=self.store)
                    print(f"ðŸ–¼ï¸  Using image-based generation")
                except Exception as e:
                    return f"Failed to load image generator: {e}", [], ""
            else:
                # Use existing text-based generator (or create new one with store)
                try:
                    from impl.generator_qwen_vl import QwenVLGenerator
                    generator = QwenVLGenerator(self.config, use_images=False, store=self.store)
                    print(f"ðŸ“ Using text-based generation with context assembly")
                except Exception as e:
                    # Fallback to original generator
                    generator = self.generator
                    print(f"ðŸ“ Using text-based generation")
            
            # Create temporary pipeline with selected generator
            from core.pipeline import Pipeline
            pipeline = Pipeline(
                retriever=retriever,
                selector=self.selector,
                generator=generator,
                logger=self.logger,
                store=self.store
            )
            
            # Parse doc filter
            doc_ids = None
            if doc_filter.strip():
                doc_ids = [d.strip() for d in doc_filter.split(",") if d.strip()]
            
            # Create query input
            query_input = QueryInput(
                query_id=str(uuid.uuid4()),
                question=question,
                doc_ids=doc_ids
            )
            
            # Run pipeline
            result = pipeline.answer(query_input, self.config)
            
            # Format evidence table
            evidence_rows = []
            if result.evidence and result.evidence.evidence:
                for i, ev in enumerate(result.evidence.evidence, 1):
                    # For image mode, show page info instead of snippet
                    if evidence_mode == "image":
                        snippet_text = f"[Image Mode] Page {ev.page_id}"
                    else:
                        snippet_text = ev.snippet[:100] + "..." if len(ev.snippet) > 100 else ev.snippet
                    
                    evidence_rows.append([
                        i,
                        f"{retrieval_mode} + {evidence_mode}",  # Show both modes
                        ev.doc_id,
                        ev.page_id,
                        f"{ev.score:.4f}",
                        snippet_text
                    ])
            
            answer = result.generation.output.answer if result.generation else "No answer generated."
            
            # Debug: check what's in the result
            if not result.generation:
                print(f"âš ï¸  Warning: result.generation is None")
            elif not result.generation.output:
                print(f"âš ï¸  Warning: result.generation.output is None")
            elif not result.generation.output.answer:
                print(f"âš ï¸  Warning: answer is empty")
            else:
                print(f"âœ… Generated answer: {answer[:100]}...")
            
            return answer, evidence_rows, query_input.query_id
            
        except Exception as e:
            import traceback
            error_msg = f"Error: {str(e)}\n{traceback.format_exc()}"
            return error_msg, [], ""

    def _handle_eval(
        self,
        eval_file,
        eval_mode: str,
        fusion_method: str = "weighted_sum",
        retriever_1: str = "bm25",
        retriever_2: str = "dense",
        weight_1: float = 0.4
    ) -> Tuple[str, dict, Optional[str], Optional[str]]:
        """Handle batch evaluation with custom hybrid configuration."""
        try:
            if eval_file is None:
                return "Error: No evaluation file uploaded", {}, None, None
            
            # Get or create retriever with custom hybrid config
            retriever = self.retrievers.get(eval_mode)
            
            # For hybrid modes, create custom configuration
            if "hybrid" in eval_mode:
                from impl.retriever_hybrid import HybridRetriever
                
                # Validate different retrievers
                if retriever_1 == retriever_2:
                    return f"âš ï¸ è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ£€ç´¢å™¨ï¼å½“å‰éƒ½é€‰æ‹©äº† {retriever_1}", {}, None, None
                
                # Ensure retrievers are loaded
                retriever_objs = {}
                for ret_name in [retriever_1, retriever_2]:
                    if ret_name == "colpali" and self.retrievers.get("colpali") is None:
                        if hasattr(self, "_colpali_config"):
                            try:
                                print(f"â³ Loading ColPali for evaluation...")
                                from impl.index_colpali import ColPaliRetriever
                                colpali_retriever = ColPaliRetriever.load(
                                    self._colpali_config["index_dir"],
                                    model_name=self._colpali_config["model_name"],
                                    device=self._colpali_config["device"]
                                )
                                self.retrievers["colpali"] = colpali_retriever
                                print(f"âœ… ColPali loaded")
                            except Exception as e:
                                return f"Failed to load ColPali: {e}", {}, None, None
                        else:
                            return f"ColPali not configured.", {}, None, None
                    
                    if ret_name not in self.retrievers:
                        return f"âš ï¸ æ£€ç´¢å™¨ '{ret_name}' æœªæ‰¾åˆ°ï¼Œè¯·å…ˆæž„å»ºç´¢å¼•", {}, None, None
                    
                    retriever_objs[ret_name] = self.retrievers[ret_name]
                
                # Calculate weights
                weight_2 = 1.0 - weight_1
                weights = {retriever_1: weight_1, retriever_2: weight_2}
                
                # Create hybrid retriever
                retriever = HybridRetriever(
                    retrievers=retriever_objs,
                    weights=weights,
                    fusion_method=fusion_method
                )
                
                print(f"ðŸ“Š Evaluation Hybrid Config:")
                print(f"   {retriever_1} ({weight_1:.2f}) + {retriever_2} ({weight_2:.2f})")
                print(f"   Fusion: {fusion_method}")
            
            if not retriever:
                return f"Error: Retrieval mode '{eval_mode}' not available", {}, None, None
            
            self.pipeline.retriever = retriever
            
            # Run evaluation
            from impl.eval_runner import load_dataset_from_csv, load_dataset_from_json
            
            if eval_file.name.endswith('.csv'):
                dataset = load_dataset_from_csv(eval_file.name)
            else:
                dataset = load_dataset_from_json(eval_file.name)
            
            report = self.eval_runner.run(dataset, self.config)
            
            # Save results
            report_dir = Path(self.config.reports_dir) / f"eval_{uuid.uuid4().hex[:8]}"
            report_dir.mkdir(parents=True, exist_ok=True)
            
            csv_path = str(report_dir / "predictions.csv")
            json_path = str(report_dir / "report.json")
            
            self.eval_runner.save_results(report, report_dir)
            
            status = f"âœ… Evaluation complete\n"
            status += f"Mode: {eval_mode}\n"
            if "hybrid" in eval_mode:
                status += f"Config: {retriever_1}({weight_1:.2f}) + {retriever_2}({weight_2:.2f}), {fusion_method}\n"
            status += f"Samples: {len(dataset)}\n"
            status += f"Results saved to: {report_dir}"
            
            return status, report.metrics, csv_path, json_path
            
        except Exception as e:
            import traceback
            error_msg = f"Error: {str(e)}\n{traceback.format_exc()}"
            return error_msg, {}, None, None

    def _check_ocr_service(self) -> bool:
        """Check if OCR service is available."""
        import requests
        
        endpoint = self.config.ocr.get('endpoint', 'http://localhost:8000')
        
        try:
            response = requests.get(f"{endpoint}/health", timeout=3)
            return response.status_code == 200
        except:
            return False

    def _get_doc_list(self) -> List:
        """Get list of documents."""
        try:
            docs = self.store.list_documents()
            rows = []
            for meta in docs:
                rows.append([
                    meta.doc_id,
                    meta.title,
                    meta.page_count,
                    meta.created_at
                ])
            return rows
        except Exception as e:
            print(f"Error listing documents: {e}")
            return []


def main():
    """Launch UI."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Launch Doc RAG UI V1")
    parser.add_argument("--config", default="configs/app.yaml", help="Config file path")
    parser.add_argument("--share", action="store_true", help="Create shareable link")
    
    args = parser.parse_args()
    
    ui = DocRAGUIV1(args.config)
    ui.launch(share=args.share)


if __name__ == "__main__":
    main()
